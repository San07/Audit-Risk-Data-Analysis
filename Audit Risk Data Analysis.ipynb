{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 31\n",
    "### Sanika Moghe\n",
    "### Chaitanya Vyas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 2\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 1.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Classification Task:\n",
    "- Apply two voting classifiers - one with hard voting and one with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 1. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Deliverables:\n",
    "- Use markdown to provide inline comments for this project.\n",
    "- Your outputs should be clearly executed in the notebook i.e. we should not need to rerun the code to obtain the outputs.\n",
    "- Visualization encouraged.\n",
    "- If you are submitting two different files, then please only one group member submit both the files. If you submit two files separately from different accounts, it will be submitted as two different attempts.\n",
    "- If you are submitting two different files, then please follow below naming convetion:\n",
    "    Project2_Regression_GroupXX_Firstname1_Firstname2.ipynb\n",
    "    Project2_Classification_GroupXX_Firstname1_Firstname2.ipynb\n",
    "- If you are submitting single file, then please follow below naming convetion:\n",
    "    Project2_Both_GroupXX_Firstname1_Firstname2.ipynb\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(\"audit_risk.csv\") \n",
    "b=pd.read_csv(\"trial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>...</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>Marks</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>History_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.508</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7148</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.480</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5060</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  \\\n",
       "0          3.89          23    4.18      0.6   2.508    2.50      0.2   0.500   \n",
       "1          3.89           6    0.00      0.2   0.000    4.83      0.2   0.966   \n",
       "2          3.89           6    0.51      0.2   0.102    0.23      0.2   0.046   \n",
       "3          3.89           6    0.00      0.2   0.000   10.80      0.6   6.480   \n",
       "4          3.89           6    0.00      0.2   0.000    0.08      0.2   0.016   \n",
       "\n",
       "   TOTAL  numbers  ...  Audit_Risk  Risk  SCORE_A  SCORE_B  Marks  \\\n",
       "0   6.68      5.0  ...      1.7148     1        6        2      2   \n",
       "1   4.83      5.0  ...      0.5108     0        2        2      2   \n",
       "2   0.74      5.0  ...      0.3096     0        2        2      2   \n",
       "3  10.80      6.0  ...      3.5060     1        2        6      6   \n",
       "4   0.08      5.0  ...      0.2832     0        2        2      2   \n",
       "\n",
       "   MONEY_Marks  District  Loss  LOSS_SCORE  History_score  \n",
       "0            2         2     0           2              2  \n",
       "1            2         2     0           2              2  \n",
       "2            2         2     0           2              2  \n",
       "3            6         2     0           2              2  \n",
       "4            2         2     0           2              2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common = a.columns.intersection(b.columns).tolist()\n",
    "final = pd.merge(a, b, how = 'inner',on=common)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 629 entries, 0 to 628\n",
      "Data columns (total 35 columns):\n",
      "Sector_score      629 non-null float64\n",
      "LOCATION_ID       626 non-null object\n",
      "PARA_A            629 non-null float64\n",
      "Score_A           629 non-null float64\n",
      "Risk_A            629 non-null float64\n",
      "PARA_B            629 non-null float64\n",
      "Score_B           629 non-null float64\n",
      "Risk_B            629 non-null float64\n",
      "TOTAL             629 non-null float64\n",
      "numbers           629 non-null float64\n",
      "Score_B.1         629 non-null float64\n",
      "Risk_C            629 non-null float64\n",
      "Money_Value       628 non-null float64\n",
      "Score_MV          629 non-null float64\n",
      "Risk_D            629 non-null float64\n",
      "District_Loss     629 non-null int64\n",
      "PROB              629 non-null float64\n",
      "RiSk_E            629 non-null float64\n",
      "History           629 non-null int64\n",
      "Prob              629 non-null float64\n",
      "Risk_F            629 non-null float64\n",
      "Score             629 non-null float64\n",
      "Inherent_Risk     629 non-null float64\n",
      "CONTROL_RISK      629 non-null float64\n",
      "Detection_Risk    629 non-null float64\n",
      "Audit_Risk        629 non-null float64\n",
      "Risk              629 non-null int64\n",
      "SCORE_A           629 non-null int64\n",
      "SCORE_B           629 non-null int64\n",
      "Marks             629 non-null int64\n",
      "MONEY_Marks       629 non-null int64\n",
      "District          629 non-null int64\n",
      "Loss              629 non-null int64\n",
      "LOSS_SCORE        629 non-null int64\n",
      "History_score     629 non-null int64\n",
      "dtypes: float64(23), int64(11), object(1)\n",
      "memory usage: 176.9+ KB\n"
     ]
    }
   ],
   "source": [
    "final = final.replace(r'[^\\d.]+',np.nan,regex=True)\n",
    "final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sector_score      False\n",
       "LOCATION_ID        True\n",
       "PARA_A            False\n",
       "Score_A           False\n",
       "Risk_A            False\n",
       "PARA_B            False\n",
       "Score_B           False\n",
       "Risk_B            False\n",
       "TOTAL             False\n",
       "numbers           False\n",
       "Score_B.1         False\n",
       "Risk_C            False\n",
       "Money_Value        True\n",
       "Score_MV          False\n",
       "Risk_D            False\n",
       "District_Loss     False\n",
       "PROB              False\n",
       "RiSk_E            False\n",
       "History           False\n",
       "Prob              False\n",
       "Risk_F            False\n",
       "Score             False\n",
       "Inherent_Risk     False\n",
       "CONTROL_RISK      False\n",
       "Detection_Risk    False\n",
       "Audit_Risk        False\n",
       "Risk              False\n",
       "SCORE_A           False\n",
       "SCORE_B           False\n",
       "Marks             False\n",
       "MONEY_Marks       False\n",
       "District          False\n",
       "Loss              False\n",
       "LOSS_SCORE        False\n",
       "History_score     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 625 entries, 0 to 628\n",
      "Data columns (total 35 columns):\n",
      "Sector_score      625 non-null float64\n",
      "LOCATION_ID       625 non-null object\n",
      "PARA_A            625 non-null float64\n",
      "Score_A           625 non-null float64\n",
      "Risk_A            625 non-null float64\n",
      "PARA_B            625 non-null float64\n",
      "Score_B           625 non-null float64\n",
      "Risk_B            625 non-null float64\n",
      "TOTAL             625 non-null float64\n",
      "numbers           625 non-null float64\n",
      "Score_B.1         625 non-null float64\n",
      "Risk_C            625 non-null float64\n",
      "Money_Value       625 non-null float64\n",
      "Score_MV          625 non-null float64\n",
      "Risk_D            625 non-null float64\n",
      "District_Loss     625 non-null int64\n",
      "PROB              625 non-null float64\n",
      "RiSk_E            625 non-null float64\n",
      "History           625 non-null int64\n",
      "Prob              625 non-null float64\n",
      "Risk_F            625 non-null float64\n",
      "Score             625 non-null float64\n",
      "Inherent_Risk     625 non-null float64\n",
      "CONTROL_RISK      625 non-null float64\n",
      "Detection_Risk    625 non-null float64\n",
      "Audit_Risk        625 non-null float64\n",
      "Risk              625 non-null int64\n",
      "SCORE_A           625 non-null int64\n",
      "SCORE_B           625 non-null int64\n",
      "Marks             625 non-null int64\n",
      "MONEY_Marks       625 non-null int64\n",
      "District          625 non-null int64\n",
      "Loss              625 non-null int64\n",
      "LOSS_SCORE        625 non-null int64\n",
      "History_score     625 non-null int64\n",
      "dtypes: float64(23), int64(11), object(1)\n",
      "memory usage: 175.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>Marks</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>History_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.00000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.458752</td>\n",
       "      <td>2.638337</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>1.490003</td>\n",
       "      <td>13.189666</td>\n",
       "      <td>0.320640</td>\n",
       "      <td>7.767216</td>\n",
       "      <td>15.788643</td>\n",
       "      <td>5.082400</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>...</td>\n",
       "      <td>8.747667</td>\n",
       "      <td>0.491200</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>3.206400</td>\n",
       "      <td>2.28800</td>\n",
       "      <td>3.110400</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>2.070400</td>\n",
       "      <td>2.204800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.583572</td>\n",
       "      <td>6.295894</td>\n",
       "      <td>0.180853</td>\n",
       "      <td>3.805486</td>\n",
       "      <td>55.547565</td>\n",
       "      <td>0.176794</td>\n",
       "      <td>33.354451</td>\n",
       "      <td>56.883767</td>\n",
       "      <td>0.291455</td>\n",
       "      <td>0.088085</td>\n",
       "      <td>...</td>\n",
       "      <td>42.943459</td>\n",
       "      <td>0.500323</td>\n",
       "      <td>1.808527</td>\n",
       "      <td>1.767937</td>\n",
       "      <td>0.88085</td>\n",
       "      <td>1.710349</td>\n",
       "      <td>1.330124</td>\n",
       "      <td>0.197315</td>\n",
       "      <td>0.402123</td>\n",
       "      <td>0.748701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.890000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.570000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.752000</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.448000</td>\n",
       "      <td>11.120000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.971600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.850000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1264.630000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>758.778000</td>\n",
       "      <td>1268.910000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>961.514400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sector_score      PARA_A     Score_A      Risk_A       PARA_B  \\\n",
       "count    625.000000  625.000000  625.000000  625.000000   625.000000   \n",
       "mean      21.458752    2.638337    0.339200    1.490003    13.189666   \n",
       "std       24.583572    6.295894    0.180853    3.805486    55.547565   \n",
       "min        1.850000    0.000000    0.200000    0.000000     0.000000   \n",
       "25%        2.720000    0.000000    0.200000    0.000000     0.000000   \n",
       "50%        3.890000    0.650000    0.200000    0.130000     0.430000   \n",
       "75%       55.570000    2.920000    0.600000    1.752000     6.720000   \n",
       "max       59.850000   85.000000    0.600000   51.000000  1264.630000   \n",
       "\n",
       "          Score_B      Risk_B        TOTAL     numbers   Score_B.1  ...  \\\n",
       "count  625.000000  625.000000   625.000000  625.000000  625.000000  ...   \n",
       "mean     0.320640    7.767216    15.788643    5.082400    0.228800  ...   \n",
       "std      0.176794   33.354451    56.883767    0.291455    0.088085  ...   \n",
       "min      0.200000    0.000000     0.000000    5.000000    0.200000  ...   \n",
       "25%      0.200000    0.000000     0.210000    5.000000    0.200000  ...   \n",
       "50%      0.200000    0.086000     1.050000    5.000000    0.200000  ...   \n",
       "75%      0.600000    3.448000    11.120000    5.000000    0.200000  ...   \n",
       "max      0.600000  758.778000  1268.910000    9.000000    0.600000  ...   \n",
       "\n",
       "       Audit_Risk        Risk     SCORE_A     SCORE_B      Marks  MONEY_Marks  \\\n",
       "count  625.000000  625.000000  625.000000  625.000000  625.00000   625.000000   \n",
       "mean     8.747667    0.491200    3.392000    3.206400    2.28800     3.110400   \n",
       "std     42.943459    0.500323    1.808527    1.767937    0.88085     1.710349   \n",
       "min      0.280000    0.000000    2.000000    2.000000    2.00000     2.000000   \n",
       "25%      0.299200    0.000000    2.000000    2.000000    2.00000     2.000000   \n",
       "50%      0.444800    0.000000    2.000000    2.000000    2.00000     2.000000   \n",
       "75%      4.971600    1.000000    6.000000    6.000000    2.00000     4.000000   \n",
       "max    961.514400    1.000000    6.000000    6.000000    6.00000     6.000000   \n",
       "\n",
       "         District        Loss  LOSS_SCORE  History_score  \n",
       "count  625.000000  625.000000  625.000000     625.000000  \n",
       "mean     2.560000    0.033600    2.070400       2.204800  \n",
       "std      1.330124    0.197315    0.402123       0.748701  \n",
       "min      2.000000    0.000000    2.000000       2.000000  \n",
       "25%      2.000000    0.000000    2.000000       2.000000  \n",
       "50%      2.000000    0.000000    2.000000       2.000000  \n",
       "75%      2.000000    0.000000    2.000000       2.000000  \n",
       "max      6.000000    2.000000    6.000000       6.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.info()\n",
    "final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sector_score      False\n",
       "LOCATION_ID       False\n",
       "PARA_A            False\n",
       "Score_A           False\n",
       "Risk_A            False\n",
       "PARA_B            False\n",
       "Score_B           False\n",
       "Risk_B            False\n",
       "TOTAL             False\n",
       "numbers           False\n",
       "Score_B.1         False\n",
       "Risk_C            False\n",
       "Money_Value       False\n",
       "Score_MV          False\n",
       "Risk_D            False\n",
       "District_Loss     False\n",
       "PROB              False\n",
       "RiSk_E            False\n",
       "History           False\n",
       "Prob              False\n",
       "Risk_F            False\n",
       "Score             False\n",
       "Inherent_Risk     False\n",
       "CONTROL_RISK      False\n",
       "Detection_Risk    False\n",
       "Audit_Risk        False\n",
       "Risk              False\n",
       "SCORE_A           False\n",
       "SCORE_B           False\n",
       "Marks             False\n",
       "MONEY_Marks       False\n",
       "District          False\n",
       "Loss              False\n",
       "LOSS_SCORE        False\n",
       "History_score     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final.loc[:, ~final.columns.isin(['Audit_Risk', 'Risk'])]\n",
    "y = final.loc[:, final.columns.isin(['Audit_Risk', 'Risk'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.08460127e-02 3.81754398e-03 2.58190667e-04 1.18868703e-01\n",
      " 2.11054387e-05 4.78079243e-03 1.55135873e-01 6.33476451e-03\n",
      " 1.09645381e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 6.06503660e-04 1.56917533e-01 7.21197388e-04 6.04558439e-02\n",
      " 2.86760521e-03 3.25530184e-02 1.07284519e-03 5.69065163e-04\n",
      " 6.38146390e-04 7.73242743e-02 5.89919885e-03 1.80786474e-02\n",
      " 0.00000000e+00 1.13492226e-01 3.20666972e-02 1.64666859e-03\n",
      " 1.14497586e-01 4.95654200e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier(random_state=0)\n",
    "model.fit(X, y['Risk'])\n",
    "print(model.feature_importances_)\n",
    "%matplotlib inline\n",
    "def plot_feature_importances(model):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    n_features = X.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), X.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PARA_A', 'Risk_A'),\n",
       " ('Score_A', 'SCORE_A'),\n",
       " ('PARA_B', 'Risk_B'),\n",
       " ('PARA_B', 'TOTAL'),\n",
       " ('Score_B', 'Score'),\n",
       " ('Score_B', 'SCORE_B'),\n",
       " ('Risk_B', 'TOTAL'),\n",
       " ('numbers', 'Score_B.1'),\n",
       " ('numbers', 'Risk_C'),\n",
       " ('numbers', 'Marks'),\n",
       " ('Score_B.1', 'Risk_C'),\n",
       " ('Score_B.1', 'Marks'),\n",
       " ('Risk_C', 'Marks'),\n",
       " ('Money_Value', 'Risk_D'),\n",
       " ('Score_MV', 'MONEY_Marks'),\n",
       " ('District_Loss', 'RiSk_E'),\n",
       " ('District_Loss', 'District'),\n",
       " ('PROB', 'Loss'),\n",
       " ('PROB', 'LOSS_SCORE'),\n",
       " ('RiSk_E', 'District'),\n",
       " ('History', 'Risk_F'),\n",
       " ('Prob', 'History_score'),\n",
       " ('Score', 'SCORE_B'),\n",
       " ('Loss', 'LOSS_SCORE')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = final.corr().abs()\n",
    "high_corr = np.where(correlation>0.9)\n",
    "high_corr=[(correlation.columns[x],correlation.columns[y]) for x,y in zip(*high_corr) if x!=y and x<y]\n",
    "high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new= ['District','MONEY_Marks','TOTAL','Inherent_Risk', 'Prob', 'Score', 'CONTROL_RISK', 'District_Loss', 'Score_MV']\n",
    "X = X.loc[:, new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_regr_train = y_train['Audit_Risk']\n",
    "y_regr_test = y_test['Audit_Risk']\n",
    "\n",
    "y_cls_train = y_train['Risk'].astype(np.int64)\n",
    "y_cls_test = y_test['Risk'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_trainval = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)), ('knn', KNeighb...bf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft', weights=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_trainval, y_cls_train)\n",
    "knn_clf = KNeighborsClassifier(7)\n",
    "knn_clf.fit(X_trainval, y_cls_train)\n",
    "svm_clf = SVC(C = 10, probability = True)\n",
    "svm_clf.fit(X_trainval,y_cls_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='soft')\n",
    "voting_clf.fit(X_trainval, y_cls_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.984\n",
      "KNeighborsClassifier 1.0\n",
      "SVC 0.984\n",
      "VotingClassifier 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_trainval, y_cls_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_cls_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)), ('knn', KNeighb...bf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf1 = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='hard')\n",
    "voting_clf1.fit(X_trainval, y_cls_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.984\n",
      "KNeighborsClassifier 1.0\n",
      "SVC 0.984\n",
      "VotingClassifier 0.984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_clf1):\n",
    "    clf.fit(X_trainval, y_cls_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_cls_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(1, 10)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': range(1, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state = 0), param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_trainval, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "bag_clf = BaggingClassifier(grid_search, n_estimators=500, max_samples=100, bootstrap=True, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_cls_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_cls_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_cls_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_trainval, y_cls_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_cls_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging for Random Forests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests\n",
    "dt_clf = DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=0)\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=0)\n",
    "rnd_clf.fit(X_trainval, y_cls_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred == y_pred_rf ) / len(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out of the bag evaluation\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, bootstrap=True, n_jobs=-1, oob_score=True, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_cls_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasting for Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAsting\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=100, bootstrap=False, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_cls_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_cls_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasting for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAsting for Random Forest\n",
    "dt_clf = DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=0)\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=1.0, bootstrap=False, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=0)\n",
    "rnd_clf.fit(X_trainval, y_cls_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred == y_pred_rf ) / len(y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging for K Nearest Neighbour Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400, 500, 600], 'max_samples': [10, 20, 40, 50, 60, 70, 90, 100, 200, 300]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging for KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = dict(n_estimators=[100,200,300,400,500,600],max_samples=[10,20,40,50,60,70,90,100,200,300])\n",
    "\n",
    "bag_clf = BaggingClassifier(KNeighborsClassifier(n_neighbors=1), bootstrap=True, random_state=0)\n",
    "grid_search = GridSearchCV(bag_clf, param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_trainval, y_cls_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 50, 'n_estimators': 200}\n",
      "Best Mean Train F1-score: 1.0000\n",
      "Best Mean Validation F1-score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Mean Train F1-score: {:.4f}\".format(grid_search.cv_results_['mean_train_score'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation F1-score: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_cls_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_cls_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400, 500, 600], 'max_samples': [10, 20, 40, 50, 60, 70, 90, 100, 200, 300]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(KNeighborsClassifier(n_neighbors=1), bootstrap=False, random_state=0)\n",
    "grid_search = GridSearchCV(bag_clf, param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_trainval, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cls_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_trainval, y_cls_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_cls_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5,random_state=2)\n",
    "ada_clf.fit(X_trainval, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cls_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {:.2f}'.format(ada_clf.score(X_trainval, y_cls_train)))\n",
    "print('Test score: {:.2f}'.format(ada_clf.score(X_test, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboosting for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "svc=SVC(probability=True,kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)\n",
    "model = ada.fit(X_trainval, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_cls_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt.fit(X_trainval, y_cls_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_trainval, y_cls_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 0s 571us/sample - loss: 0.7965 - acc: 0.3880\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.7838 - acc: 0.5160\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.7713 - acc: 0.5160\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.7598 - acc: 0.5160\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.7487 - acc: 0.5320\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.7387 - acc: 0.5340\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.7295 - acc: 0.5340\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.7204 - acc: 0.5420\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 0s 0s/sample - loss: 0.7120 - acc: 0.5580\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.7036 - acc: 0.5740\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 0s 13us/sample - loss: 0.6959 - acc: 0.6520\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 0s 63us/sample - loss: 0.6881 - acc: 0.7340\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.6805 - acc: 0.8420\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.6734 - acc: 0.9040\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 0s 0s/sample - loss: 0.6662 - acc: 0.9260\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 0s 44us/sample - loss: 0.6589 - acc: 0.9420\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.6517 - acc: 0.9640\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.6441 - acc: 0.9720\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 0s 31us/sample - loss: 0.6360 - acc: 0.9740\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 0s 0s/sample - loss: 0.6275 - acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x281229f2cc0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1: build the model\n",
    "model1 = Sequential()\n",
    "#input leyer\n",
    "model1.add(Dense(10, input_dim = 9, activation = 'relu'))\n",
    "#hidden layer\n",
    "model1.add(Dense(5, activation = 'relu'))\n",
    "#output layer\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# step 2: build the computational graph - compile\n",
    "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])\n",
    "\n",
    "# step 3: train the model\n",
    "model1.fit(X_trainval, y_cls_train, epochs = 20, batch_size = 100)\n",
    "\n",
    "# step 4: model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 107us/sample - loss: 0.6219 - acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6218742814064026, 0.976]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_trainval, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 0s/sample - loss: 0.5977 - acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5977206635475159, 0.976]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717948717948718"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_train_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "precision_score(y_cls_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before and After PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#create model\n",
    "pca = PCA(n_components= 0.95, random_state = 0)\n",
    "\n",
    "#train pca model\n",
    "pca.fit(X)\n",
    "X_c=pca.transform(X)\n",
    "\n",
    "X_train_c, X_test_c, y_train, y_test = train_test_split(X_c, y, random_state = 0, test_size = 0.2)\n",
    "y_cls_train = y_train['Risk'].astype(np.int64)\n",
    "y_cls_test = y_test['Risk'].astype(np.int64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#create model\n",
    "pca = PCA(n_components= 0.95, random_state = 0)\n",
    "\n",
    "#train pca model\n",
    "pca.fit(X_trainval)\n",
    "\n",
    "#transforming X_train and X_test\n",
    "X_train_c = pca.transform(X_train)\n",
    "X_test_ = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': range(1, 20)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors': range(1, 20)}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_train_c, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 1}\n",
      "Best Mean Train F1-score: 1.0000\n",
      "Best Mean Validation F1-score: 0.9962\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Mean Train F1-score: {:.4f}\".format(grid_search.cv_results_['mean_train_score'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation F1-score: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        60\n",
      "           1       0.94      1.00      0.97        65\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       125\n",
      "   macro avg       0.97      0.97      0.97       125\n",
      "weighted avg       0.97      0.97      0.97       125\n",
      "\n",
      "Accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(1)\n",
    "knn.fit(X_train_c, y_cls_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_cls_test, knn.predict(X_test_c)))\n",
    "print('Accuracy: {:.4f}'.format(knn.score(X_test_c, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Before PCA\n",
    "Best parameters: {'n_neighbors': 1}\n",
    "Best Mean Train F1-score: 1.0000\n",
    "Best Mean Validation F1-score: 0.9956\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        60\n",
    "           1       1.00      1.00      1.00        65\n",
    "\n",
    "   micro avg       1.00      1.00      1.00       125\n",
    "   macro avg       1.00      1.00      1.00       125\n",
    "weighted avg       1.00      1.00      1.00       125\n",
    "\n",
    "Accuracy: 1.0000\n",
    "\n",
    "Results After PCA\n",
    "Best parameters: {'n_neighbors': 1}\n",
    "Best Mean Train F1-score: 1.0000\n",
    "Best Mean Validation F1-score: 0.9683\n",
    "  precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.93      0.97        60\n",
    "           1       0.94      1.00      0.97        65\n",
    "\n",
    "   micro avg       0.97      0.97      0.97       125\n",
    "   macro avg       0.97      0.97      0.97       125\n",
    "weighted avg       0.97      0.97      0.97       125\n",
    "\n",
    "Accuracy: 0.9680\n",
    "The mean train score,test score and accuracy were 1 before applying PCA, indicating overfitting of data.\n",
    "After performing PCA, the accuracy is 0.968.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "             'penalty': ['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_train_c, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1000, 'penalty': 'l2'}\n",
      "Best Mean Train F1-score: 0.9933\n",
      "Best Mean Validation F1-score: 0.9936\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Mean Train F1-score: {:.4f}\".format(grid_search.cv_results_['mean_train_score'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation F1-score: {:.4f}\".format(grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        60\n",
      "           1       1.00      0.92      0.96        65\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       125\n",
      "   macro avg       0.96      0.96      0.96       125\n",
      "weighted avg       0.96      0.96      0.96       125\n",
      "\n",
      "Accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lreg = LogisticRegression(penalty = 'l1', C = 10)\n",
    "lreg.fit(X_train_c, y_cls_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_cls_test, lreg.predict(X_test_c)))\n",
    "print('Accuracy: {:.4f}'.format(lreg.score(X_test_c, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results before PCA:\n",
    "Best parameters: {'C': 0.001, 'penalty': 'l2'}\n",
    "\n",
    "Best Mean Train F1-score: 1.0000\n",
    "\n",
    "Best Mean Validation F1-score: 1.0000\n",
    "\n",
    "        precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        60\n",
    "           1       1.00      1.00      1.00        65\n",
    "\n",
    "    micro avg      1.00      1.00      1.00       125\n",
    "   \n",
    "    macro avg      1.00      1.00      1.00       125\n",
    "   \n",
    "    weighted avg   1.00      1.00      1.00       125\n",
    "\n",
    "Accuracy: 1.0000\n",
    "\n",
    "After PCA:\n",
    "Best parameters: {'C': 1000, 'penalty': 'l2'}\n",
    "\n",
    "Best Mean Train F1-score: 0.9933\n",
    "\n",
    "Best Mean Validation F1-score: 0.9936\n",
    "\n",
    "      precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      1.00      0.96        60\n",
    "           1       1.00      0.92      0.96        65\n",
    "\n",
    "    micro avg      0.96      0.96      0.96       125\n",
    "    macro avg      0.96      0.96      0.96       125\n",
    "    weighted avg   0.96      0.96      0.96       125\n",
    "\n",
    "Accuracy: 0.9600\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "grid_search = GridSearchCV(LinearSVC(), param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_train_c, y_cls_train)\n",
    "train_score_array = []\n",
    "test_score_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100}\n",
      "Best Mean Train F1-score: 0.9231\n",
      "Best Mean Validation F1-score: 0.9225\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Mean Train F1-score: {:.4f}\".format(grid_search.cv_results_['mean_train_score'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation F1-score: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        60\n",
      "           1       1.00      0.92      0.96        65\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       125\n",
      "   macro avg       0.96      0.96      0.96       125\n",
      "weighted avg       0.96      0.96      0.96       125\n",
      "\n",
      "Accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C = 1)\n",
    "lsvc.fit(X_train_c,y_cls_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_cls_test, lsvc.predict(X_test_c)))\n",
    "print('Accuracy: {:.4f}'.format(lsvc.score(X_test_c, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:\n",
    "Best parameters: {'C': 1}\n",
    "Best Mean Train F1-score: 1.0000\n",
    "Best Mean Validation F1-score: 0.9956\n",
    "      precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        60\n",
    "           1       1.00      1.00      1.00        65\n",
    "\n",
    "     micro avg       1.00      1.00      1.00       125\n",
    "     macro avg       1.00      1.00      1.00       125\n",
    "     weighted avg       1.00      1.00      1.00       125\n",
    "\n",
    "Accuracy: 1.0000\n",
    "\n",
    "After PCA:\n",
    "Best parameters: {'C': 1000}\n",
    "Best Mean Train F1-score: 0.9232\n",
    "Best Mean Validation F1-score: 0.9203\n",
    "\n",
    "     precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      1.00      0.96        60\n",
    "           1       1.00      0.92      0.96        65\n",
    "\n",
    "     micro avg       0.96      0.96      0.96       125\n",
    "     macro avg       0.96      0.96      0.96       125\n",
    "    weighted avg       0.96      0.96      0.96       125\n",
    "\n",
    "Accuracy: 0.9600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernelized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf', 'poly']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                 'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                 'kernel': ['linear', 'rbf', 'poly']}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_train_c, y_cls_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Best Mean Train F1-score: 1.0000\n",
      "Best Mean Validation F1-score: 0.9981\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Mean Train F1-score: {:.4f}\".format(grid_search.cv_results_['mean_train_score'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation F1-score: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        60\n",
      "           1       0.89      1.00      0.94        65\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       125\n",
      "   macro avg       0.95      0.93      0.94       125\n",
      "weighted avg       0.94      0.94      0.94       125\n",
      "\n",
      "Accuracy: 0.9360\n"
     ]
    }
   ],
   "source": [
    "ksvc_rbf = SVC(kernel = 'rbf', C = 0.1, gamma = 10)\n",
    "ksvc_rbf.fit(X_train_c,y_cls_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_cls_test, ksvc_rbf.predict(X_test_c)))\n",
    "print('Accuracy: {:.4f}'.format(ksvc_rbf.score(X_test_c, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:\n",
    "Best parameters: {'C': 1, 'gamma': 10, 'kernel': 'rbf'}\n",
    "Best Mean Train F1-score: 1.0000\n",
    "Best Mean Validation F1-score: 1.0000\n",
    "\n",
    "       precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.98      0.99        60\n",
    "           1       0.98      1.00      0.99        65\n",
    "\n",
    "   micro avg       0.99      0.99      0.99       125\n",
    "   macro avg       0.99      0.99      0.99       125\n",
    "weighted avg       0.99      0.99      0.99       125\n",
    "\n",
    "Accuracy: 0.9920\n",
    "After PCA:\n",
    "Best parameters: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
    "Best Mean Train F1-score: 1.0000\n",
    "Best Mean Validation F1-score: 0.9981\n",
    "        precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.87      0.93        60\n",
    "           1       0.89      1.00      0.94        65\n",
    "\n",
    "   micro avg       0.94      0.94      0.94       125\n",
    "   macro avg       0.95      0.93      0.94       125\n",
    "weighted avg       0.94      0.94      0.94       125\n",
    "\n",
    "Accuracy: 0.9360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': range(1, 10)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {'max_depth': range(1, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state = 0), param_grid, cv=kfold, return_train_score=True, scoring='f1')\n",
    "grid_search.fit(X_train_c, y_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 4}\n",
      "Best Mean Train F1-score: 0.9984\n",
      "Best Mean Validation F1-score: 0.9832\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Mean Train F1-score: {:.4f}\".format(grid_search.cv_results_['mean_train_score'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation F1-score: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94        60\n",
      "           1       0.93      0.97      0.95        65\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       125\n",
      "   macro avg       0.95      0.94      0.94       125\n",
      "weighted avg       0.94      0.94      0.94       125\n",
      "\n",
      "Accuracy: 0.9440\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state = 0, max_depth = 2)\n",
    "dtree.fit(X_train_c, y_cls_train)\n",
    "\n",
    "print(classification_report(y_cls_test, dtree.predict(X_test_c)))\n",
    "print('Accuracy: {:.4f}'.format(dtree.score(X_test_c, y_cls_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:\n",
    "Best parameters: {'max_depth': 1}\n",
    "Best Mean Train F1-score: 1.0000\n",
    "Best Mean Validation F1-score: 0.9976\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        60\n",
    "           1       1.00      1.00      1.00        65\n",
    "\n",
    "   micro avg       1.00      1.00      1.00       125\n",
    "   macro avg       1.00      1.00      1.00       125\n",
    "weighted avg       1.00      1.00      1.00       125\n",
    "\n",
    "Accuracy: 1.0000\n",
    "\n",
    "After PCA:\n",
    "Best parameters: {'max_depth': 4}\n",
    "Best Mean Train F1-score: 0.9984\n",
    "Best Mean Validation F1-score: 0.9832\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.92      0.94        60\n",
    "           1       0.93      0.97      0.95        65\n",
    "\n",
    "    micro avg      0.94      0.94      0.94       125\n",
    "    macro avg      0.95      0.94      0.94       125\n",
    "    weighted avg   0.94      0.94      0.94       125\n",
    "\n",
    "Accuracy: 0.9440\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion : The models before PCA seem to be overfitting the data. After applying PCA the accuracy has been reduced but it gives a better result than before PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = final.loc[:, ~final.columns.isin(['Audit_Risk', 'Risk'])]\n",
    "y = final.loc[:, final.columns.isin(['Audit_Risk', 'Risk'])]\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "model = ExtraTreesRegressor(random_state=0)\n",
    "model.fit(X, y['Audit_Risk'])\n",
    "\n",
    "%matplotlib inline\n",
    "def plot_feature_importances(model):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    n_features = X.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), X.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PARA_A', 'Risk_A'),\n",
       " ('Score_A', 'SCORE_A'),\n",
       " ('PARA_B', 'Risk_B'),\n",
       " ('PARA_B', 'TOTAL'),\n",
       " ('Score_B', 'Score'),\n",
       " ('Score_B', 'SCORE_B'),\n",
       " ('Risk_B', 'TOTAL'),\n",
       " ('numbers', 'Score_B.1'),\n",
       " ('numbers', 'Risk_C'),\n",
       " ('numbers', 'Marks'),\n",
       " ('Score_B.1', 'Risk_C'),\n",
       " ('Score_B.1', 'Marks'),\n",
       " ('Risk_C', 'Marks'),\n",
       " ('Money_Value', 'Risk_D'),\n",
       " ('Score_MV', 'MONEY_Marks'),\n",
       " ('District_Loss', 'RiSk_E'),\n",
       " ('District_Loss', 'District'),\n",
       " ('PROB', 'Loss'),\n",
       " ('PROB', 'LOSS_SCORE'),\n",
       " ('RiSk_E', 'District'),\n",
       " ('History', 'Risk_F'),\n",
       " ('Prob', 'History_score'),\n",
       " ('Score', 'SCORE_B'),\n",
       " ('Loss', 'LOSS_SCORE')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = final.corr().abs()\n",
    "high_corr_var = np.where(corr_matrix>0.9)\n",
    "high_corr_var=[(corr_matrix.columns[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "high_corr_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_regression = ['TOTAL','Inherent_Risk', 'Prob', 'Score', 'CONTROL_RISK', 'District_Loss', 'Score_MV']\n",
    "X = X.loc[:, features_for_regression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "data_outliers_removed = final[(np.abs(stats.zscore(final.loc[:, features_for_regression])) < 3).all(axis=1)]\n",
    "\n",
    "X = data_outliers_removed.loc[:, features_for_regression]\n",
    "y = data_outliers_removed.loc[:, ['Audit_Risk', 'Risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
    "y_regr_train = y_train['Audit_Risk']\n",
    "y_regr_test = y_test['Audit_Risk']\n",
    "\n",
    "y_cls_train = y_train['Risk'].astype(np.int64)\n",
    "y_cls_test = y_test['Risk'].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_trainval = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging for KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'n_neighbors': range(1, 20)}\n",
    "#kn= KNeighborsRegressor()\n",
    "#bag=BaggingRegressor(base_estimator=kn,bootstrap=True,random_state=0)\n",
    "#grid_search = GridSearchCV(bag, param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "#grid_search.fit(X_trainval, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960837335928554\n",
      "0.8983561799541195\n"
     ]
    }
   ],
   "source": [
    "bag=BaggingRegressor(grid_search,bootstrap=True,random_state=0)\n",
    "bag.fit(X_trainval, y_regr_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print(bag.score(X_trainval, y_regr_train))\n",
    "print(bag.score(X_test, y_regr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging for Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
    "                                max_features=1.0,\n",
    "                                bootstrap_features=False,\n",
    "                                bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(X_trainval, y_regr_train)\n",
    "y_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933322215180806\n",
      "0.9597619492607283\n"
     ]
    }
   ],
   "source": [
    "print(ensemble.score(X_trainval, y_regr_train))\n",
    "print(ensemble.score(X_test, y_regr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasting for KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7988646960852234\n"
     ]
    }
   ],
   "source": [
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'n_neighbors': range(1, 20)}\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "\n",
    "bag=BaggingRegressor(grid_search,bootstrap=False,random_state=0)\n",
    "bag.fit(X_trainval, y_regr_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "print(bag.score(X_trainval, y_regr_train))\n",
    "print(bag.score(X_test, y_regr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasting for Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
    "                                max_features=1.0,\n",
    "                                bootstrap_features=False,\n",
    "                                bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999997389608\n",
      "0.9592342764486567\n"
     ]
    }
   ],
   "source": [
    "ensemble.fit(X_trainval, y_regr_train)\n",
    "y_pred = ensemble.predict(X_test)\n",
    "print(ensemble.score(X_trainval, y_regr_train))\n",
    "print(ensemble.score(X_test, y_regr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboosting for KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "          weights='unifo...', return_train_score=True,\n",
       "       scoring={'R2': 'r2', 'MSE': 'neg_mean_squared_error'}, verbose=0),\n",
       "         learning_rate=1.0, loss='linear', n_estimators=50,\n",
       "         random_state=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'n_neighbors': range(1, 20)}\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "\n",
    "#ada = AdaBoostRegressor(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada=AdaBoostRegressor(grid_search, n_estimators=50, learning_rate=1.0, random_state=None)\n",
    "ada.fit(X_trainval, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998057693637036\n",
      "0.827424158348029\n"
     ]
    }
   ],
   "source": [
    "y_pred = ada.predict(X_test)\n",
    "print(ada.score(X_trainval, y_regr_train))\n",
    "print(ada.score(X_test, y_regr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboosting for Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999612577253478\n",
      "0.9698931927757681\n"
     ]
    }
   ],
   "source": [
    "ada_d=AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=50, learning_rate=1.0, random_state=None)\n",
    "ada_d.fit(X_trainval, y_regr_train)\n",
    "y_pred = ada_d.predict(X_test)\n",
    "print(ada_d.score(X_trainval, y_regr_train))\n",
    "print(ada_d.score(X_test, y_regr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998397471131852\n",
      "0.9390827732007905\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X_trainval, y_regr_train)\n",
    "y_pred=gbrt.predict(X_test)\n",
    "print(gbrt.score(X_trainval, y_regr_train))\n",
    "print(gbrt.score(X_test, y_regr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results After PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X = final.loc[:, ~final.columns.isin(['Audit_Risk', 'Risk'])]\n",
    "y = final.loc[:, final.columns.isin(['Audit_Risk', 'Risk'])]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
    "y_regr_train = y_train['Audit_Risk']\n",
    "y_regr_test = y_test['Audit_Risk']\n",
    "\n",
    "y_cls_train = y_train['Risk'].astype(np.int64)\n",
    "y_cls_test = y_test['Risk'].astype(np.int64)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_trainval = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#create model\n",
    "pca = PCA(n_components= 0.95, random_state = 0)\n",
    "\n",
    "#train pca model\n",
    "pca.fit(X_trainval)\n",
    "\n",
    "#transforming X_train and X_test\n",
    "X_train_r = pca.fit_transform(X_trainval)\n",
    "X_test_r = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': range(1, 20)}, pre_dispatch='2*n_jobs',\n",
       "       refit='R2', return_train_score=True,\n",
       "       scoring={'R2': 'r2', 'MSE': 'neg_mean_squared_error'}, verbose=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'n_neighbors': range(1, 20)}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "grid_search.fit(X_train_r, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 2}\n",
      "Best Mean Train MSE: -446.0538\n",
      "Best Mean Train R2: 0.8155\n",
      "Best Mean Validation MSE: -1794.7817\n",
      "Best Mean Validation R2: 0.5879\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "print(\"Best Mean Train MSE: {:.4f}\".format(grid_search.cv_results_['mean_train_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Train R2: {:.4f}\".format(grid_search.cv_results_['mean_train_R2'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation MSE: {:.4f}\".format(grid_search.cv_results_['mean_test_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation R2: {:.4f}\".format(grid_search.cv_results_['mean_test_R2'][grid_search.best_index_]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results before PCA are -\n",
    "\n",
    "Best parameters: {'n_neighbors': 1}\n",
    "Best Mean Train MSE: 0.0000\n",
    "Best Mean Train R2: 1.0000\n",
    "Best Mean Validation MSE: -1727.7694\n",
    "Best Mean Validation R2: 0.6434\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train MSE: -143.0230\n",
      "Mean Train R2: 0.9036\n",
      "Mean Validation MSE: -1103.6636\n",
      "Mean Validation R2: 0.4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_MSE'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_R2'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_r, y_regr_train)\n",
    "\n",
    "cv_result = cross_validate(lreg, X_train_r, y_regr_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(\"Mean Train MSE: {:.4f}\".format(np.mean(cv_result['train_MSE'])))\n",
    "print(\"Mean Train R2: {:.4f}\".format(np.mean(cv_result['train_R2'])))\n",
    "\n",
    "print(\"Mean Validation MSE: {:.4f}\".format(np.mean(cv_result['test_MSE'])))\n",
    "print(\"Mean Validation R2: {:.4f}\".format(np.mean(cv_result['test_R2'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:\n",
    "Mean Train MSE: -102.2738\n",
    "Mean Train R2: 0.9313\n",
    "Mean Validation MSE: -1015.9507\n",
    "Mean Validation R2: 0.4288\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit='R2', return_train_score=True,\n",
       "       scoring={'R2': 'r2', 'MSE': 'neg_mean_squared_error'}, verbose=0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "grid_search.fit(X_train_r, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.001}\n",
      "Best Mean Train MSE: -143.0230\n",
      "Best Mean Train R2: 0.9036\n",
      "Best Mean Validation MSE: -1104.2546\n",
      "Best Mean Validation R2: 0.4411\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "print(\"Best Mean Train MSE: {:.4f}\".format(grid_search.cv_results_['mean_train_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Train R2: {:.4f}\".format(grid_search.cv_results_['mean_train_R2'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation MSE: {:.4f}\".format(grid_search.cv_results_['mean_test_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation R2: {:.4f}\".format(grid_search.cv_results_['mean_test_R2'][grid_search.best_index_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA\n",
    "Best parameters: {'alpha': 1}\n",
    "Best Mean Train MSE: -133.9901\n",
    "Best Mean Train R2: 0.9074\n",
    "Best Mean Validation MSE: -1349.7861\n",
    "Best Mean Validation R2: 0.4629\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit='R2', return_train_score=True,\n",
       "       scoring={'R2': 'r2', 'MSE': 'neg_mean_squared_error'}, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "grid_search.fit(X_train_r, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Train MSE: -416.8423\n",
      "Best Mean Train R2: 0.7828\n",
      "Best Mean Validation MSE: -1636.9996\n",
      "Best Mean Validation R2: 0.5388\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best Mean Train MSE: {:.4f}\".format(grid_search.cv_results_['mean_train_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Train R2: {:.4f}\".format(grid_search.cv_results_['mean_train_R2'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation MSE: {:.4f}\".format(grid_search.cv_results_['mean_test_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation R2: {:.4f}\".format(grid_search.cv_results_['mean_test_R2'][grid_search.best_index_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA\n",
    "Best parameters: {'alpha': 1000}\n",
    "Best Mean Train MSE: -411.7122\n",
    "Best Mean Train R2: 0.7857\n",
    "Best Mean Validation MSE: -1635.9847\n",
    "Best Mean Validation R2: 0.5446"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='squared_loss', max_iter=100000,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=-inf, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2', 'elasticnet'], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit='R2', return_train_score=True,\n",
       "       scoring={'R2': 'r2', 'MSE': 'neg_mean_squared_error'}, verbose=0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "             'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(SGDRegressor(random_state= 0, max_iter = 100000, tol=-np.infty,learning_rate = 'optimal'), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "grid_search.fit(X_train_r, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.1, 'penalty': 'l1'}\n",
      "Best Mean Train MSE: -155.2730\n",
      "Best Mean Train R2: 0.8722\n",
      "Best Mean Validation MSE: -191.1993\n",
      "Best Mean Validation R2: 0.5415\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "print(\"Best Mean Train MSE: {:.4f}\".format(grid_search.cv_results_['mean_train_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Train R2: {:.4f}\".format(grid_search.cv_results_['mean_train_R2'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation MSE: {:.4f}\".format(grid_search.cv_results_['mean_test_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation R2: {:.4f}\".format(grid_search.cv_results_['mean_test_R2'][grid_search.best_index_]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:\n",
    "Best parameters: {'alpha': 10, 'penalty': 'l2'}\n",
    "Best Mean Train MSE: -1052.3989\n",
    "Best Mean Train R2: 0.5040\n",
    "Best Mean Validation MSE: -1810.3217\n",
    "Best Mean Validation R2: 0.5217\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=100000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit='R2', return_train_score=True,\n",
       "       scoring={'R2': 'r2', 'MSE': 'neg_mean_squared_error'}, verbose=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'C' : [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(LinearSVR(max_iter = 100000), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "grid_search.fit(X_train_r, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100}\n",
      "Best Mean Train MSE: -916.1215\n",
      "Best Mean Train R2: 0.5899\n",
      "Best Mean Validation MSE: -1243.3953\n",
      "Best Mean Validation R2: 0.6685\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "print(\"Best Mean Train MSE: {:.4f}\".format(grid_search.cv_results_['mean_train_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Train R2: {:.4f}\".format(grid_search.cv_results_['mean_train_R2'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation MSE: {:.4f}\".format(grid_search.cv_results_['mean_test_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation R2: {:.4f}\".format(grid_search.cv_results_['mean_test_R2'][grid_search.best_index_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:\n",
    "Best parameters: {'C': 100}\n",
    "Best Mean Train MSE: -794.7863\n",
    "Best Mean Train R2: 0.6560\n",
    "Best Mean Validation MSE: -1245.2013\n",
    "Best Mean Validation R2: 0.6858\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernelized Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10], 'gamma': [0.01, 0.1, 1, 10], 'kernel': ['rbf', 'linear']},\n",
       "       pre_dispatch='2*n_jobs', refit='R2', return_train_score=True,\n",
       "       scoring={'R2': 'r2', 'MSE': 'neg_mean_squared_error'}, verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error'}\n",
    "param_grid = {'C' : [0.01, 0.1, 1, 10], \n",
    "              'gamma' : [0.01, 0.1, 1, 10],\n",
    "              'kernel' : ['rbf', 'linear']}\n",
    "\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=kfold, return_train_score=True, scoring=scoring, refit='R2')\n",
    "grid_search.fit(X_train_r, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Best Mean Train MSE: -916.0105\n",
      "Best Mean Train R2: 0.5898\n",
      "Best Mean Validation MSE: -1243.2194\n",
      "Best Mean Validation R2: 0.6680\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "print(\"Best Mean Train MSE: {:.4f}\".format(grid_search.cv_results_['mean_train_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Train R2: {:.4f}\".format(grid_search.cv_results_['mean_train_R2'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation MSE: {:.4f}\".format(grid_search.cv_results_['mean_test_MSE'][grid_search.best_index_]))\n",
    "print(\"Best Mean Validation R2: {:.4f}\".format(grid_search.cv_results_['mean_test_R2'][grid_search.best_index_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:\n",
    "Best parameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'linear'}\n",
    "Best Mean Train MSE: -1307.3916\n",
    "Best Mean Train R2: 0.4413\n",
    "Best Mean Validation MSE: -1348.4878\n",
    "Best Mean Validation R2: 0.6594\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sanik\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28124330978>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = 33, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))  \n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam' , metrics = ['mse'])\n",
    "model.fit(X_trainval, y_regr_train, epochs = 30, batch_size = 50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 125us/sample - loss: 2223.3490 - mean_squared_error: 2223.3491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2223.3489642944337, 2223.349]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_trainval, y_regr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 0s/sample - loss: 612.2713 - mean_squared_error: 612.2713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[612.271322265625, 612.2713]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_regr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: PCA reduces the train and test score for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
